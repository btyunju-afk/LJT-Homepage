{
  "basics": {
    "name": "Junteng Liu",
    "email": "jliugi@connect.ust.hk",
    "phone": "",
    "website": "https://btyunju-afk.github.io",
    "summary": "First-year PhD candidate at HKUST NLP Group. Research focuses on natural language processing and machine learning, with interests in LLM reasoning, reinforcement learning, and VLM hallucination. Previously graduated from Shanghai Jiao Tong University with B.Eng. degree.",
    "location": {
      "address": "",
      "postalCode": "",
      "city": "Hong Kong",
      "countryCode": "HK",
      "region": ""
    },
    "profiles": [
      {
        "network": "Google Scholar",
        "username": "Junteng Liu",
        "url": "https://scholar.google.com/citations?hl=en&user=tbK9jl4AAAAJ&view_op=list_works&sortby=pubdate"
      },
      {
        "network": "GitHub",
        "username": "Vicent0205",
        "url": "https://github.com/Vicent0205"
      },
      {
        "network": "X (Twitter)",
        "username": "junteng88716710",
        "url": "https://twitter.com/junteng88716710"
      }
    ]
  },
  "work": [
    {
      "name": "Research Intern",
      "position": "Research Intern",
      "url": "https://www.minimaxi.com",
      "startDate": "2025-02-01",
      "endDate": "Present",
      "summary": "Research internship focusing on natural language processing and machine learning research.",
      "highlights": [
        "Conducting research on LLM reasoning and reinforcement learning",
        "Working on hallucination in Vision-Language Models (VLM)",
        "Investigating LLM truthfulness and interpretability"
      ]
    },
    {
      "name": "Tencent WXG",
      "position": "Research Intern",
      "url": "https://wx.qq.com",
      "startDate": "2024-06-01",
      "endDate": "2024-09-01",
      "summary": "Research internship at Tencent WeChat Work (WXG) under the guidance of Zifei Shan.",
      "highlights": [
        "Conducted research in natural language processing",
        "Collaborated with senior researchers on machine learning projects",
        "Published research work during the internship period"
      ]
    },
    {
      "name": "Shanghai AI Lab",
      "position": "Research Intern",
      "url": "https://www.shailab.cn",
      "startDate": "2023-06-01",
      "endDate": "2023-12-01",
      "summary": "Research internship at Shanghai AI Lab under the guidance of Prof. Yu Cheng.",
      "highlights": [
        "Engaged in cutting-edge AI research projects",
        "Contributed to research publications",
        "Collaborated with leading AI researchers"
      ]
    }
  ],
  "education": [
    {
      "institution": "Hong Kong University of Science and Technology",
      "area": "Ph.D. in Computer Science",
      "studyType": "Doctor of Philosophy",
      "startDate": "2024-09-01",
      "endDate": "Present",
      "gpa": null,
      "courses": [],
      "summary": "First-year PhD candidate at HKUST NLP Group, supervised by Professor Junxian He. Research focuses on natural language processing and machine learning."
    },
    {
      "institution": "Shanghai Jiao Tong University",
      "area": "Bachelor of Engineering",
      "studyType": "Bachelor of Engineering",
      "startDate": "2020-09-01",
      "endDate": "2024-06-01",
      "gpa": null,
      "courses": [],
      "summary": "Graduated with B.Eng. degree. Received Zhiyuan Honor Scholarship for academic excellence."
    }
  ],
  "skills": [
    {
      "name": "Natural Language Processing",
      "level": "Advanced",
      "keywords": ["Transformers", "LLMs", "Text Classification", "Sentiment Analysis", "Machine Translation"]
    },
    {
      "name": "Machine Learning",
      "level": "Advanced", 
      "keywords": ["Deep Learning", "Reinforcement Learning", "Neural Networks", "Optimization"]
    },
    {
      "name": "Programming Languages",
      "level": "Advanced",
      "keywords": ["Python", "PyTorch", "TensorFlow", "JAX"]
    },
    {
      "name": "Research Areas",
      "level": "Advanced",
      "keywords": ["LLM Reasoning", "VLM Hallucination", "Truthfulness", "Interpretability"]
    }
  ],
  "languages": [
    {
      "language": "English",
      "fluency": "Professional working proficiency"
    },
    {
      "language": "Chinese (Mandarin)",
      "fluency": "Native"
    }
  ],
  "interests": [
    {
      "name": "LLM Reasoning and Reinforcement Learning",
      "keywords": ["Large Language Models", "Reasoning", "RLHF", "Chain-of-Thought"]
    },
    {
      "name": "Hallucination in Vision-Language Models",
      "keywords": ["VLM", "Multimodal Learning", "Truthfulness", "Reliability"]
    },
    {
      "name": "LLM Truthfulness and Interpretability",
      "keywords": ["Interpretability", "Model Analysis", "Truthfulness", "Robustness"]
    }
  ],
  "references": [
    {
      "name": "Professor Junxian He",
      "relationship": "PhD Supervisor",
      "email": "junxianhe@ust.hk",
      "organization": "HKUST NLP Group"
    },
    {
      "name": "Zifei Shan",
      "relationship": "Research Mentor",
      "organization": "Tencent WXG"
    },
    {
      "name": "Prof. Yu Cheng",
      "relationship": "Research Mentor",
      "organization": "Shanghai AI Lab"
    }
  ],
  "publications": [
    {
      "name": "SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning Logical Reasoning and Beyond",
      "publisher": "ArXiv",
      "releaseDate": "2025-01-01",
      "website": "https://arxiv.org/abs/XXXX.XXXXX",
      "summary": "First author paper on synthesizing verifiable reasoning data for logical reasoning in large language models. The work introduces methods for generating large-scale, verifiable reasoning datasets and demonstrates improvements in logical reasoning capabilities.",
      "authors": ["Junteng Liu", "Yuanxiang Fan", "Zhuo Jiang", "Han Ding", "Yongyi Hu", "Chi Zhang", "Yiqi Shi", "Shitong Weng", "Aili Chen", "Shiqi Chen", "Yunan Huang", "Mozhi Zhang", "Pengyu Zhao", "Junjie Yan", "Junxian He"],
      "github": "https://github.com/Vicent0205/SynLogic"
    },
    {
      "name": "On the Perception Bottleneck of VLMs for Chart Understanding",
      "publisher": "ArXiv",
      "releaseDate": "2025-01-01",
      "website": "https://arxiv.org/abs/XXXX.XXXXX",
      "summary": "First author paper investigating the perception bottlenecks in Vision-Language Models for chart understanding tasks. The work analyzes current limitations and proposes solutions for improving VLM performance on chart comprehension.",
      "authors": ["Junteng Liu", "Weihao Zeng", "Xiwen Zhang", "Yijun Wang", "Zifei Shan", "Junxian He"],
      "github": "https://github.com/Vicent0205/Vision4Chart"
    },
    {
      "name": "On the Universal Truthfulness Hyperplane Inside LLMs",
      "publisher": "EMNLP 2024",
      "releaseDate": "2024-11-01",
      "website": "https://arxiv.org/abs/XXXX.XXXXX",
      "summary": "First author paper discovering and analyzing the universal truthfulness hyperplane inside large language models. This work provides insights into how truthfulness is encoded in LLM representations.",
      "authors": ["Junteng Liu", "Shiqi Chen", "Yu Cheng", "Junxian He"],
      "github": "https://github.com/Vicent0205/Universal_Truthfulness_Hyperplane"
    },
    {
      "name": "In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation",
      "publisher": "ICML 2024",
      "releaseDate": "2024-07-01",
      "website": "https://arxiv.org/abs/XXXX.XXXXX",
      "summary": "Co-authored paper proposing a method for detecting and mitigating hallucinations in language models by analyzing in-context sharpness in inner representations.",
      "authors": ["Shiqi Chen", "Miao Xiong", "Junteng Liu", "Zhengxuan Wu", "Teng Xiao", "Siyang Gao", "Junxian He"]
    },
    {
      "name": "C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models",
      "publisher": "NeurIPS 2023",
      "releaseDate": "2023-12-01",
      "website": "https://arxiv.org/abs/XXXX.XXXXX",
      "summary": "Co-authored paper introducing C-Eval, a comprehensive evaluation suite for assessing foundation models' capabilities across multiple disciplines in Chinese.",
      "authors": ["Yuzhen Huang", "Yuzhuo Bai", "Zhihao Zhu", "Junlei Zhang", "Jinghan Zhang", "Tangjun Su", "Junteng Liu", "Chuancheng Lv", "Yikai Zhang", "Jiayi Lei", "Yao Fu", "Maosong Sun", "Junxian He"]
    },
    {
      "name": "Composing Parameter-Efficient Modules with Arithmetic Operations",
      "publisher": "NeurIPS 2023",
      "releaseDate": "2023-12-01",
      "website": "https://arxiv.org/abs/XXXX.XXXXX",
      "summary": "Co-authored paper exploring methods for composing parameter-efficient modules using arithmetic operations to improve model efficiency and performance.",
      "authors": ["Jinghan Zhang", "Shiqi Chen", "Junteng Liu", "Junxian He"]
    }
  ],
  "presentations": [],
  "teaching": [],
  "portfolio": []
}