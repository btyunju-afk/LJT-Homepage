---
title: "In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation"
collection: publications
category: conferences
permalink: /publication/2024-07-01-in-context-sharpness
excerpt: 'Co-authored paper proposing a method for detecting and mitigating hallucinations in language models by analyzing in-context sharpness in inner representations.'
date: 2024-07-01
venue: 'ICML 2024'
paperurl: 'https://arxiv.org/abs/XXXX.XXXXX'
citation: 'Chen, S., Xiong, M., Liu, J., Wu, Z., Xiao, T., Gao, S., & He, J. (2024). In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation. In International Conference on Machine Learning (ICML).'
---

The contents above will be part of a list of publications, if the user clicks the link for the publication than the contents of section will be rendered as a full page, allowing you to provide more information about the paper for the reader. When publications are displayed as a single page, the contents of the above "citation" field will automatically be included below this section in a smaller font.

This paper proposes a novel method for detecting and mitigating hallucinations in language models by analyzing in-context sharpness in inner representations. The work provides a new perspective on understanding and addressing hallucination problems in LLMs.